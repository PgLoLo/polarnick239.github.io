---
layout: ru/blogs/courses/gpgpu2018/post
title:  "Лекция 1: История"
date:   2018-07-20 21:30:00 +0300
lang:   ru
id:     19_gpgpu2018_lecture1
---

## Процессоры

Долго процессоры были одноядерными, и тактовая частота была их основной характеристикой.

Но в 2004 году рост частоты остановился на 3.6 ГГц ([Pentium 4 Prescott](https://en.wikipedia.org/wiki/Pentium_4#Prescott)):

<img alt="CPU clock speed graph" src="/static/courses/gpgpu2018/lecture1/cpu_clock_speed.png" width="600"/>

На самом деле процессоры не просто исполняют операции подряд одну за другой с некоторой частотой. Т.е. не только от частоты работы процессора зависит его эффективная скорость работы:

1. [Instruction-level parallelism](https://en.wikipedia.org/wiki/Instruction-level_parallelism) позволяет за счет out-of-order исполнения команд меньше простаивать.
2. Оптимизации связанные с попыткой процессора угадывать куда дальше в условных ветвлениях пойдет код позволяют out-of-order исполнению работать даже при частом условном ветвлении.
3. Часто вычисления упираются не в способность процессора молотить числа, а в то как быстро данные подгружаются из оперативной памяти в регистры процессора (даже несмотря на out-of-order). Поэтому важны L1/L2/L3 кеши и оптимизации связанные с memory-prefetching.
4. В теории скрывать задержки обращения к памяти так же пытается [Hyper-threading](https://en.wikipedia.org/wiki/Hyper-threading) и [SMT](https://en.wikipedia.org/wiki/Simultaneous_multithreading) за счет дешевого переключения контекста на поток у которого все данные уже под рукой. Но на практике ускорение редко заметно.
4. [Single instruction, multiple data](https://en.wikipedia.org/wiki/SIMD) - в случаях когда процессор все-таки упирается в вычислительную мощность,
 например делая одинаковые тяжелые вычисления в большом массиве данных (например в картинке), полезно иметь более мощную версию операции $$a \cdot b$$, которая
 производит умножение сразу над 2/4/8/16/32 парами значений (т.е. $$a_0 \cdot b_0$$, $$a_1 \cdot b_1$$, $$a_2 \cdot b_2$$, $$a_3 \cdot b_3$$, ...). Такие специальные инструкции были добавлены в расширениях:
 
   - 1997, ``MMX`` - регистры 64 бита, целочисленные операции, т.е. за раз над ``8 x char``/``4 x short``/``2 x int``
   - 1999, ``SSE`` - регистры 128 бит, операции над числами с плавающей точкой, т.е. за раз над ``4 x float``
   - 2000, ``SSE2`` - регистры 128 бит, теперь и над целыми, и над float/double, т.е. за раз над ``16 x char``/``8 x short``/``4 x int``/``2 x long``/``4 x float``/``2 x double``
   - 2004-2006, ``SSE3`` / ``SSSE3`` / ``SSE4`` / ``SSE4.1`` / ``SSE4.2`` - расширения набора инструкций (горизонтальная работа с регистрами, специальные функции для видеокодирования и обработки строк)
   - 2011, ``AVX`` - регистры 256 бит, только над float/double, т.е. за раз над ``8 x float``/``4 x double``
   - 2013, ``AVX2`` - регистры 256 бит, теперь и над целыми, и над float/double, т.е. за раз над ``32 x char``/``16 x short``/``8 x int``/``4 x long``/``8 x float``/``4 x double``
   - 2017, ``AVX-512`` - регистры 512 бит, много подрасширений, мало где есть, условно за раз над ``16 x float``/``8 x double``

5. И, наконец, многоядерность. В типичном компьютере выросла до четырех ядер в 2008 году и застряла там до 2017 года в связи с отсутствием конкуренции. 

## Software 3D

<img alt="Quake" src="/static/courses/gpgpu2018/lecture1/quake.png" width="300"/>

Вплоть до 1996 года даже игры вроде DOOM, Quake и Duke Nukem 3D обсчитывали визуализацию 3D пространства на процессоре. Процессор справлялся в первую очередь благодаря низкому расширению экрана (320x200) и относительно простой графике. Получить представление о том как это работало можно по [этому видео](https://www.youtube.com/watch?v=HQYsFshbkYw).

## Специализированные 3D-ускорители

Около 1995-1997 начали набирать популярность специализированные 3D-ускорители (такие как S3 ViRGE, ATI 3D Rage, 3dfx Voodoo) способные отрисовывать более сложную графику гораздо эффективнее.

## 3D-ускорители стали программируемыми (шейдеры)

Спецэффекты в играх становились все сложнее и стало невозможно продолжать предлагать программистам лишь жестко [ограниченный набор](https://www.khronos.org/opengl/wiki/Fixed_Function_Pipeline) 3D функциональности, возникла потребность дать гибкий инструмент для программирования видеокарты.

Так появились программируемые шейдеры. Стало возможно в каждом пикселе посчитать произвольную математику, и это позволило делать много интересных спецэффектов.
 
## Зарождение GPGPU

Благодаря популярности игр, архитектурным особенностям видеокарт (задача отрисовки обладает массовым параллелизмом, т.к. пиксели на экране можно обсчитывать независимо) и все возрастающей сложности игровой графики производительность видеокарт росла гораздо быстрее процессоров:

<img alt="GPU gflops graph" src="/static/courses/gpgpu2018/lecture1/cpu_gpu_gflops_old.png" width="600"/>

И поэтому видеокарты специализирурующиеся на отображении 3D-графики начали использовать и для других задач, таких как обсчет физики и моделирования сложных процессов.

Это стало возможно благодаря гибкости программируемых шейдеров, но тем не менее из-за специализации на 3D-графике гибкость шейдеров была ограничена,
 и для general-purpose задач возникла потребность нового, еще более гибкого API.

## Появление GPGPU API

Стали появляться API лучше подходящие для general-purpose вычислений:

 - 2006, ``Close to Metal`` - поддерживался только на видеокартах от AMD, позже был заменен на OpenCL
 - 2007, ``CUDA`` - поддерживается только на видеокартах от NVidia
 - 2009, ``OpenCL`` - открытый стандарт поддерживающийся практически везде

Так же позже появилось несколько узко специализированных API: 

 - 2011, ``RenderScript`` - специально для Android, изначально ставил целью заменить OpenGL, с 2013 года стал пытаться заменить OpenCL
 - 2014, ``Metal`` - специально для устройств Apple, и графика, и вычисления

В результате на сегодняшний день для вычислений общего назначения обладающих массовым параллелизмом на видеокартах существуют удобные API, и реализовать потенциал видеокарты с их помощью
гораздо проще чем теоретическую мощность процессора с помощью SIMD.

Производительность видеокарт же на порядок выше по обоим критическим показателям - вычислительная мощность и пропускная способность видеопамяти:

<img alt="CPU clock speed graph" src="/static/courses/gpgpu2018/lecture1/cpu_gpu_gflops.png"/>

<img alt="CPU clock speed graph" src="/static/courses/gpgpu2018/lecture1/cpu_gpu_memory_bandwidth.png"/>

# Следующая [лекция 2. Введение в OpenCL](/blogs/courses/gpgpu2018/2018/07/21/lecture2-opencl-introduction-ru.html).

## Ссылки:

 - [https://superuser.com/a/906227](https://superuser.com/a/906227)
 - [http://www.lipid.wabash.edu/gpu.html](http://www.lipid.wabash.edu/gpu.html)
 - [https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/](https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/)
